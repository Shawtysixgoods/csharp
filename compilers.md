## Модели исполнения

Любая программа начинается как текстовый файл, а заканчивается тем, что процессор выполняет нули и единицы в виде конкретных инструкций. Между этими двумя точками язык и платформа выбирают маршрут: можно каждый раз “читать и исполнять текст по ходу дела”, можно заранее перевести всё в машинный код, а можно остановиться на промежуточном байткоде и отложить последнюю стадию до момента запуска. Эти три подхода и дают интерпретацию, статическую компиляцию и JIT-компиляцию, и по сути они отличаются тем, *когда* и *где* делается тяжёлая работа по анализу и переводу кода. В одних экосистемах выбирают максимальную гибкость и простоту запуска, в других — максимальную скорость, а .NET с C# занимают середину: часть работы выполняется при сборке, часть переносится на момент запуска, чтобы можно было подстроиться под конкретную машину. На практике для начинающего программиста это означает, что под капотом всегда есть дополнительный слой, который думает о платформе и оптимизациях за вас.

Если упростить, то можно представить три сценария: “запускаем текст сразу”, “сначала собираем готовый .exe” и “сначала собираем универсальный байткод, а потом на каждой машине догоняем его до нативного вида”. Разные платформы выбирают разные сценарии, потому что по-разному расставляют приоритеты между удобством, переносимостью и скоростью.

***

## Интерпретатор: удобно запускать сразу

Интерпретатор ведёт себя как программа, которая читает ваш код почти как сценарий и сразу же выполняет написанное. Внутри он всё равно не работает “напрямую с текстом”: обычно он сначала разбирает исходник в дерево конструкций (например, выражения, условия, циклы), а затем проходит по этому дереву и для каждой конструкции решает, что конкретно нужно сделать — вычислить значение, перейти в другую ветку, вызвать функцию. Приятно то, что между правкой кода и запуском почти нет промежуточных шагов: вы меняете файл, снова нажимаете “run” и моментально видите результат, а иногда даже можете выполнять отдельные строки в интерактивной оболочке. За такую гибкость приходится платить тем, что каждый запуск и каждый проход по часто исполняемым участкам снова включает разбор и интерпретацию, поэтому при больших нагрузках и тяжёлых задачах интерпретируемые языки начинают заметно проигрывать тем, которые заранее превращают код в машинные инструкции. Поэтому интерпретаторы чаще всего используются там, где важна скорость разработки и удобство — в скриптах, автоматизации, прототипах, утилитах.

Если представить процесс по шагам, то он выглядит так: интерпретатор получает текст программы, строит внутреннее представление в виде дерева, а затем во время запуска каждый раз проходит по этому дереву и “разыгрывает” вашу программу, принимая решения на лету. При каждом новом запуске или при каждом новом проходе цикла эта работа повторяется, поэтому скорость упирается именно в постоянный анализ.

***

## Компилятор: максимальная скорость при запуске

Статический компилятор выбирает другой путь: он делает всю тяжёлую работу заранее, ещё до того, как вы запустите программу. На этапе сборки компилятор разбирает исходный код, проверяет синтаксис, типы и другие правила, затем применяет оптимизации и в итоге генерирует бинарный файл, который уже содержит машинные инструкции для конкретного процессора и операционной системы. Когда вы запускаете такой бинарник, операционная система просто загружает его в память и передаёт управление процессору, и тому больше не нужно знать ни про исходный код, ни про высокоуровневую структуру программы. Это даёт высокий уровень производительности и предсказуемое поведение: нет дополнительных слоёв, которые анализируют код во время работы, всё уже решено на этапе сборки. Но за это приходится платить тем, что итоговый файл привязан к платформе: то, что собрано под x86-64 Linux, не заработает на ARM или Windows без перекомпиляции или специальных “прослоек”. Кроме того, каждый раз, когда вы меняете код, вам снова нужно дождаться сборки, а в очень больших проектах этап компиляции сам по себе может быть заметно тяжёлым.

В терминах процесса это выглядит так: вы запускаете компилятор, он один раз проделывает всё — анализ, проверки, оптимизации, генерацию машинного кода — и сохраняет результат в файл, который потом запускается без дополнительных преобразований. При каждом запуске программа уже готова, ей не нужно “думать” по ходу выполнения, и именно поэтому она работает быстро.

***

## JIT-компилятор: промежуточный байткод и компиляция “по требованию”

JIT-компиляция — это попытка взять лучшее из двух миров: сохранить переносимость и удобный общий формат программы, но при этом получить нативную скорость на каждой конкретной машине. Вместо того чтобы сразу генерировать машинный код, компилятор переводит исходник в промежуточный байткод, который не привязан к архитектуре процессора, и уже этот байткод кладётся в итоговый файл. Когда программа запускается на конкретной машине, JIT-компилятор на стороне runtime берёт байткод и, когда впервые доходит до определённого метода, компилирует именно этот метод в машинные инструкции. После этого все последующие вызовы этого метода идут уже в скомпилированный нативный код, а JIT к нему больше не возвращается, пока вы не перезапустите приложение. Такой подход позволяет платформе смотреть на реальное поведение программы: можно больше оптимизировать те участки, которые вызываются чаще всего, и меньше вкладываться в редко используемый код. Минус в том, что первая волна запусков методов сопровождается небольшой “платой за вход” — нужно один раз скомпилировать код, поэтому приложения на таких платформах часто говорят “разогреваются” по мере работы.

Процесс здесь выглядит как двухступенчатый: сначала при сборке вы получаете байткод вместо машинного кода, а потом при первом обращении к каждому методу JIT на лету превращает этот байткод в нативные инструкции для конкретного CPU. Дальше этот результат кешируется, и программа уже работает с нативной скоростью на горячих участках, не тратя время на повторную компиляцию.

***

## Почему .NET устроен как управляемая платформа

Платформа .NET была задумана как общий фундамент для множества языков и как способ запускать один и тот же код на разных операционных системах и архитектурах, не заставляя разработчика собирать отдельные версии под каждую связку “ОС + процессор”. Вместо того чтобы каждый язык приносил в .NET собственный рантайм и собственную модель исполнения, платформа предлагает общую середину: единый промежуточный язык и общую среду выполнения. Вы пишете код, например на C#, запускаете компилятор, и он не выдаёт машинные инструкции, а генерирует универсальный байткод и метаданные. Дальше, где бы вы ни запускали эту сборку — под Windows, Linux или на другой поддерживаемой системе — реализация .NET на этой платформе берёт на себя финальный шаг: переводит байткод в машинный код и управляет его выполнением. Благодаря этому языки, работающие на .NET, получают общие возможности по безопасности, управлению памятью, профилированию и так далее, а улучшения в рантайме автоматически распространяются на весь стек.

С точки зрения разработчика это означает понятную картину: код языком компилируется “до середины” — в общий формат, а дальше за него отвечает платформа .NET на целевой системе. Именно поэтому можно взять одну и ту же сборку и запускать её на разных платформах, если там установлен соответствующий runtime.

***

## CLR: “движок”, который всё запускает

В центре .NET находится CLR (Common Language Runtime) — это компонент, который берёт на себя всю работу по запуску и сопровождению управляемого кода. Когда вы запускаете .NET-приложение, CLR загружает нужные сборки, читает встроенные в них метаданные и на основе этой информации строит внутренние таблицы типов, методов и ссылок на другие сборки. Когда код впервые доходит до вызова конкретного метода, CLR передаёт его описание JIT-компилятору, тот по инструкциям промежуточного языка генерирует машинный код, а CLR запоминает, что теперь этот метод связан с конкретным блоком нативных инструкций. В дальнейшем при вызовах этого метода CLR просто перенаправляет управление сразу в уже сгенерированный машинный код, не обращаясь больше к JIT, что даёт стабильную скорость, как у заранее скомпилированных программ. Параллельно CLR следит за памятью: сборщик мусора отслеживает объекты, до которых больше нельзя добраться из активного кода, и очищает память, освобождая разработчика от ручного освобождения, но вводя свои характерные паузы, о которых стоит помнить. Благодаря метаданным CLR также умеет делать такие вещи, как отражение (reflection), динамическая загрузка типов и взаимодействие между кодом, написанным на разных .NET-языках, как будто они части одной системы.

Картинка процесса получается такая: CLR загружает сборку, читает метаданные, при первом вызове метода отдаёт его JIT’у, запоминает ссылку на скомпилированный код и в будущем переходит сразу туда, а между делом ещё и следит за памятью и безопасностью выполнения. Для начинающего важно понимать, что CLR — это именно тот слой, который делает “магией” запуск вашего C#-кода на разных платформах.

***

## CIL: общий байткод для всех .NET-языков

Промежуточный язык, который понимает CLR, называется CIL (Common Intermediate Language), и он служит общим “форматом обмена” между компиляторами языков и рантаймом. Когда вы компилируете программу на C#, компилятор Roslyn не генерирует сразу машинные инструкции: он анализирует код, строит внутренние представления и по ним выпускает инструкции CIL и набор метаданных с описаниями всех типов, методов, полей и зависимостей. Эти инструкции ориентированы на стековую модель: они описывают, что нужно загрузить значение, сравнить его, вызвать метод, сделать ветвление, но сами по себе не привязаны ни к числу регистров, ни к конкретной архитектуре вроде x86-64 или ARM. Такой дизайн позволяет использовать один и тот же формат для разных процессоров и облегчает работу JIT-компилятора: он получает достаточно конкретное, но универсальное описание логики, которое можно эффективно перевести в нативный код. Для разработчика важно не то, как выглядят отдельные инструкции CIL, а то, что любой язык .NET, правильно компилирующийся в CIL, автоматически становится “полноправным гражданином” платформы и может работать бок о бок с C#-кодом.

Если разложить процесс, то он выглядит так: компилятор языка принимает текст программы, проверяет его и превращает в CIL плюс метаданные, записывает это в сборку, а потом CLR и JIT используют эти инструкции как исходную точку для генерации машинного кода. Благодаря этому шагу у всех .NET-языков появляется общий “низкий уровень”, на котором они встречаются с рантаймом.

***

## Как C# доходит от исходника до процессора

Для программы на C# жизненный цикл выполнения в .NET можно представить как цепочку понятных шагов. Сначала вы пишете исходный код и запускаете сборку с помощью инструментов .NET SDK, которые вызывают компилятор Roslyn; он проверяет код, следит за типами и правилами языка, делает базовые оптимизации и генерирует CIL и метаданные, упакованные в сборки. Когда вы запускаете программу, CLR загружает эти сборки, читает метаданные, настраивает внутренние структуры, связывает ссылки между типами и готовится к выполнению. Как только выполнение доходит до конкретного метода, CLR просит JIT скомпилировать CIL этого метода в машинный код для текущей архитектуры, и после этого все следующие вызовы того же метода идут напрямую в нативный код. При долгой работе приложения CLR и JIT могут использовать дополнительные приёмы, например многоуровневую компиляцию: сначала генерировать более простой и быстрый для старта код, а по мере накопления статистики заменять его на более агрессивно оптимизированную версию для горячих участков.

Если смотреть “с высоты новичка”, поток такой: C# → сборка с CIL → запуск → CLR загружает → JIT по мере надобности превращает CIL отдельных методов в машинный код → процессор выполняет эти инструкции. Важно, что вы почти никогда не думаете об этих шагах вручную, но понимание цепочки помогает объяснить, откуда берутся задержки на старте, почему есть “разогрев” и как устроена переносимость.

***

## Почему выбрана именно такая архитектура и какие есть варианты

Модель “CIL + CLR + JIT” в .NET — это продуманный компромисс между удобством, переносимостью и производительностью. Если бы C# всегда компилировался сразу в машинный код, как C или Rust, вы получили бы предельно быстрые и лёгкие по рантайму программы, но потеряли бы возможность иметь один и тот же бинарный артефакт для разных платформ, усложнили бы межъязыковое взаимодействие и лишились бы многих возможностей общей управляемой среды. Если бы C# исполнялся чистым интерпретатором, стало бы легче менять код на лету и анализировать его во время работы, но любая серьёзная нагрузка упиралась бы в постоянные накладные расходы интерпретации и сложность масштабирования. В текущей схеме компиляторы языков концентрируются на переводе в безопасный и единый CIL, а CLR и JIT отвечают за адаптацию к железу, управление памятью и выполнение, что даёт “достаточно хорошо” по всем трём направлениям, вместо максимума в одном и провала в других. При этом платформа признаёт, что и у этого подхода есть пределы, поэтому для сценариев с особыми требованиями появились режимы AOT, где CIL заранее превращается в нативный код, а роль JIT уменьшается, чтобы ускорить старт и уменьшить накладные расходы рантайма.

Для начинающего программиста полезно держать в голове простую картинку: C# не исполняется “напрямую” и не превращается сразу в чистый машинный код; он проходит через общий байткод CIL и среду CLR, которая уже на конкретной машине доводит его до процессора. Именно эта многоступенчатая цепочка объясняет и переносимость, и поведение под нагрузкой, и характерные особенности .NET-приложений, вроде разогрева, сборки мусора и важности настроек runtime.

